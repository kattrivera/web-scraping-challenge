{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @NOTE: Replace the path with your actual path to the chromedriver\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA, ULA Launch Mars 2020 Perseverance Rover Mission to Red Planet\n",
      "The agency's Mars 2020 mission is on its way. It will land at Jezero Crater in about seven months, on Feb. 18, 2021. \n"
     ]
    }
   ],
   "source": [
    "# def scrape_all():\n",
    "# 1.......Get Mars news\n",
    "marsUrl = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(marsUrl)\n",
    "    \n",
    "# scrape page into soup\n",
    "html = browser.html\n",
    "marsSoup = bs(html, \"html.parser\")\n",
    "\n",
    "# update below variables\n",
    "listItems = marsSoup.find('div', class_='list_text')\n",
    "news_title = listItems.find_all('a')[0].text\n",
    "news_p = marsSoup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA24032-640x350.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars/spaceimages/images/wallpaper/PIA24032-640x350.jpg\n"
     ]
    }
   ],
   "source": [
    "    # 2.......Get featured image\n",
    "spaceUrl = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(spaceUrl)\n",
    "\n",
    "    # Find the more info button and click that\n",
    "    \n",
    "    # Parse the resulting html with soup\n",
    "html = browser.html\n",
    "spaceSoup = bs(html, \"html.parser\")\n",
    "    \n",
    "    # Find the relative image url\n",
    "carouselItems = spaceSoup.find('div', class_='img')\n",
    "spaceImgPath = carouselItems.find_all('img')[0]['src']\n",
    "\n",
    "    # Use the base url to create an absolute url\n",
    "spaceImgURL = spaceUrl + spaceImgPath\n",
    "\n",
    "print(spaceImgPath)\n",
    "print(spaceImgURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/map/Mars/Viking/cerberus_enhanced\n",
      "https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars/search/map/Mars/Viking/cerberus_enhanced\n"
     ]
    }
   ],
   "source": [
    "    # 3.......Get hemispheres\n",
    "hemiUrl = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(hemiUrl)\n",
    "\n",
    "html = browser.html\n",
    "hemiSoup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Click the link, find the sample anchor, extract the href\n",
    "hemiresults = hemiSoup.find('div', class_='item')\n",
    "hemiImgPath = hemiresults.find_all('a')[0]['href']\n",
    "hemiImgUrl = hemiUrl + hemiImgPath\n",
    "\n",
    "print(hemiImgPath)\n",
    "print(hemiImgUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log in\n"
     ]
    }
   ],
   "source": [
    "    # 4.......Get twitter weather\n",
    "weatherUrl = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(weatherUrl)\n",
    "\n",
    "html = browser.html\n",
    "weatherSoup = bs(html, \"html.parser\")\n",
    "    # Pause for 5 seconds to let the Twitter page load before extracting the html\n",
    "time.sleep(5)\n",
    "\n",
    "    # First, find a tweet with the data-name `Mars Weather`\n",
    "weatherResults = weatherSoup.find('div', class_='css-1dbjc4n')\n",
    "# weatherResults = weatherSoup.find('main', role=\"main\")\n",
    "weatherText = weatherResults.find('span', class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\")\n",
    "latest_weather = weatherResults.find_all('span')[5].text\n",
    "# Next, search within the tweet for the p tag or span tag containing the tweet text\n",
    "    # As Twitter is frequently making changes the try/except will identify the tweet\n",
    "    # text using a regular expression pattern that includes the string 'sol' if there\n",
    "    # is no p tag with a class of 'tweet-text'\n",
    "\n",
    "#     mars_weather = \"\"\n",
    "# print(weatherResults)\n",
    "# print(weatherText)\n",
    "print(latest_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Description': 'Equatorial Diameter:', 'Value': '6,792 km'},\n",
       " {'Description': 'Polar Diameter:', 'Value': '6,752 km'},\n",
       " {'Description': 'Mass:', 'Value': '6.39 × 10^23 kg (0.11 Earths)'},\n",
       " {'Description': 'Moons:', 'Value': '2 (Phobos & Deimos)'},\n",
       " {'Description': 'Orbit Distance:', 'Value': '227,943,824 km (1.38 AU)'},\n",
       " {'Description': 'Orbit Period:', 'Value': '687 days (1.9 years)'},\n",
       " {'Description': 'Surface Temperature:', 'Value': '-87 to -5 °C'},\n",
       " {'Description': 'First Record:', 'Value': '2nd millennium BC'},\n",
       " {'Description': 'Recorded By:', 'Value': 'Egyptian astronomers'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # 5........Get mars facts\n",
    "factsUrl = \"http://space-facts.com/mars/\"\n",
    "browser.visit(factsUrl)\n",
    "    #use pd.read_html and df.to_html\n",
    "factsTable = pd.read_html(factsUrl)    \n",
    "\n",
    "facts_df = factsTable[0]\n",
    "facts_df = facts_df.rename(columns={0: \"Description\", 1: \"Value\"})\n",
    "facts_df\n",
    "\n",
    "htmlTable = facts_df.to_html(table_id=\"html_tbl_css\", justify=\"left\", index=False)\n",
    "htmlTable\n",
    "\n",
    "factsDict = facts_df.to_dict(orient='records')\n",
    "factsDict\n",
    "# new_df = df.to_d\n",
    "#     # Store all scraped data in a dictionary\n",
    "#     data = {}\n",
    "\n",
    "#     # Stop webdriver and return data\n",
    "#     browser.quit()\n",
    "\n",
    "#     return data\n",
    "#     # End Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # If running as script, print scraped data\n",
    "    print(scrape_all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
